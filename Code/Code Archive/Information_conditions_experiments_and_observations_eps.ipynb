{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "998aa58c-c1c4-41fe-9f34-1a91133c87cd",
   "metadata": {},
   "source": [
    "\n",
    "# Information Conditions - Environmental State and Action Histories\n",
    "\n",
    "> Plot learning trajectories under different information conditions of the Ecological Public Goods Game. a) Only environmental state history observable, b) only action history is observable, c) both environmental state and action histories are observable d) No information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a99f35f-d960-411d-868c-4d789c9e6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.ipynb\n",
    "%run information_conditions.ipynb import Information_Conditions\n",
    "%run base_ecopg.ipynb import ecopg\n",
    "%run helper_functions.ipynb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6d217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode: both_state_and_action_information\n",
      "Mean Final Cooperation Across Initial Conditions  0.139\n",
      "  Classification  MedianTimetoReach  Percentage\n",
      "0    Cooperation            10000.0        13.9\n",
      "1      Defection            10000.0        86.1\n",
      "\n",
      "Mode: only_action_history_information\n",
      "Mean Final Cooperation Across Initial Conditions  0.065\n",
      "  Classification  MedianTimetoReach  Percentage\n",
      "0      Defection            10000.0        80.6\n",
      "1          Mixed            10000.0        19.4\n",
      "\n",
      "Mode: only_state_information\n",
      "Mean Final Cooperation Across Initial Conditions  0.0\n",
      "  Classification  MedianTimetoReach  Percentage\n",
      "0      Defection            10000.0       100.0\n",
      "\n",
      "Mode: no_information\n",
      "Mean Final Cooperation Across Initial Conditions  0.084\n",
      "  Classification  MedianTimetoReach  Percentage\n",
      "0      Defection            10000.0        69.4\n",
      "1          Mixed            10000.0        30.6\n"
     ]
    }
   ],
   "source": [
    "#degraded choice is false\n",
    "\n",
    "for mode in ['both_state_and_action_information', 'only_action_history_information', 'only_state_information', 'no_information']:\n",
    " \n",
    "    # Initialize the information condition\n",
    "    information_condition_instance = Information_Conditions(ecopg, mode=mode)\n",
    "    mae = POstratAC_eps(env=information_condition_instance, learning_rates=0.1, discount_factors=0.9)\n",
    "\n",
    "    # Data storage\n",
    "    \n",
    "    avg_coop_time_pairs = []\n",
    "    num_samples = 8\n",
    "    initial_conditions_list = lhs_sampling(mae.Q, num_samples, mae.N)\n",
    "\n",
    "    print(f\"\\nMode: {mode}\")\n",
    "\n",
    "    # Monte Carlo Simulations\n",
    "    for initial_condition in initial_conditions_list:\n",
    "\n",
    "        # initial_condition = make_degraded_state_cooperation_probablity_zero(initial_condition, information_condition_instance.Oset[0]) #to make sure all of them start at the same position in the degraded state (shouldn't it)\n",
    "        xtraj, fixedpointreached = mae.trajectory(initial_condition, Tmax=10000, tolerance=1e-5)\n",
    "        final_point = xtraj[-1]\n",
    "        \n",
    "        avg_coop_across_states = get_average_cooperativeness(policy=final_point, obsdist=mae.obsdist(final_point), mode = mode, Oset = mae.env.Oset[0])[0]\n",
    "        time_to_reach = xtraj.shape[0]\n",
    "\n",
    "        # Store cooperativeness and time as pairs (round cooperativeness to 2 decimals)\n",
    "        avg_coop_time_pairs.append((round(avg_coop_across_states, 2), time_to_reach))\n",
    "\n",
    "    # Create DataFrame for processing\n",
    "    df = pd.DataFrame(avg_coop_time_pairs, columns=[\"AverageCooperation\", \"TimeToReach\"])\n",
    "    total_count = len(df)\n",
    "    \n",
    "    average_cooperation_across_initial_conditions = np.round(df['AverageCooperation'].agg('mean'), 3)\n",
    "    print(\"Mean Final Cooperation Across Initial Conditions \", average_cooperation_across_initial_conditions)\n",
    "\n",
    "\n",
    "    # Add a classification column\n",
    "    def classify(avg_coop):\n",
    "        if avg_coop < 0.1:\n",
    "            return \"Defection\"\n",
    "        elif avg_coop > 0.9:\n",
    "            return \"Cooperation\"\n",
    "        else:\n",
    "            return \"Mixed\"\n",
    "\n",
    "\n",
    "    df['Classification'] = df['AverageCooperation'].apply(classify)\n",
    "    average_cooperation_across_initial_conditions = df['AverageCooperation'].agg('mean')\n",
    "    # Reporting unique entries\n",
    "\n",
    "    # Overall Summary\n",
    "    summary = df.groupby('Classification')['TimeToReach'].agg(\n",
    "        MedianTimetoReach='median',\n",
    "        Percentage= lambda x: round((len(x) / total_count) * 100,1)\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eaa943",
   "metadata": {},
   "source": [
    "Extracting Final Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fe437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode: both_state_and_action_information\n",
      "Mean Final Cooperation Across Initial Conditions  0.0\n",
      "  Classification  MedianTimetoReach  Percentage\n",
      "0      Defection                1.0       100.0\n",
      "\n",
      "Mode: only_action_history_information\n",
      "Mean Final Cooperation Across Initial Conditions  0.065\n",
      "  Classification  MedianTimetoReach  Percentage\n",
      "0      Defection            10000.0        80.6\n",
      "1          Mixed            10000.0        19.4\n",
      "\n",
      "Mode: only_state_information\n",
      "Mean Final Cooperation Across Initial Conditions  0.0\n",
      "  Classification  MedianTimetoReach  Percentage\n",
      "0      Defection                1.0       100.0\n",
      "\n",
      "Mode: no_information\n",
      "Mean Final Cooperation Across Initial Conditions  0.084\n",
      "  Classification  MedianTimetoReach  Percentage\n",
      "0      Defection            10000.0        69.4\n",
      "1          Mixed            10000.0        30.6\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#degraded choice is false\n",
    "\n",
    "for mode in ['both_state_and_action_information', 'only_action_history_information', 'only_state_information', 'no_information']:\n",
    " \n",
    "    # Initialize the information condition\n",
    "    information_condition_instance = Information_Conditions(ecopg, mode=mode)\n",
    "    mae = POstratAC(env=information_condition_instance, learning_rates=0.1, discount_factors=0.9)\n",
    "\n",
    "    # Data storage\n",
    "    \n",
    "    avg_coop_time_pairs = []\n",
    "    num_samples = 8\n",
    "    initial_conditions_list = lhs_sampling(mae.Q, num_samples, mae.N)\n",
    "\n",
    "    print(f\"\\nMode: {mode}\")\n",
    "\n",
    "    # Monte Carlo Simulations\n",
    "    for initial_condition in initial_conditions_list:\n",
    "\n",
    "        # initial_condition = make_degraded_state_cooperation_probablity_zero(initial_condition, information_condition_instance.Oset[0]) #to make sure all of them start at the same position in the degraded state (shouldn't it)\n",
    "        xtraj, fixedpointreached = mae.trajectory(initial_condition, Tmax=10000, tolerance=1e-5)\n",
    "        final_point = xtraj[-1]\n",
    "        \n",
    "        avg_coop_across_states = get_average_cooperativeness(policy=final_point, obsdist=mae.obsdist(final_point), mode = mode, Oset = mae.env.Oset[0])[0]\n",
    "        time_to_reach = xtraj.shape[0]\n",
    "\n",
    "        # Store cooperativeness and time as pairs (round cooperativeness to 2 decimals)\n",
    "        avg_coop_time_pairs.append((round(avg_coop_across_states, 2), time_to_reach))\n",
    "\n",
    "    # Create DataFrame for processing\n",
    "    df = pd.DataFrame(avg_coop_time_pairs, columns=[\"AverageCooperation\", \"TimeToReach\"])\n",
    "    total_count = len(df)\n",
    "    \n",
    "    average_cooperation_across_initial_conditions = np.round(df['AverageCooperation'].agg('mean'), 3)\n",
    "    print(\"Mean Final Cooperation Across Initial Conditions \", average_cooperation_across_initial_conditions)\n",
    "\n",
    "\n",
    "    # Add a classification column\n",
    "    def classify(avg_coop):\n",
    "        if avg_coop < 0.1:\n",
    "            return \"Defection\"\n",
    "        elif avg_coop > 0.9:\n",
    "            return \"Cooperation\"\n",
    "        else:\n",
    "            return \"Mixed\"\n",
    "\n",
    "\n",
    "    df['Classification'] = df['AverageCooperation'].apply(classify)\n",
    "    average_cooperation_across_initial_conditions = df['AverageCooperation'].agg('mean')\n",
    "    # Reporting unique entries\n",
    "\n",
    "    # Overall Summary\n",
    "    summary = df.groupby('Classification')['TimeToReach'].agg(\n",
    "        MedianTimetoReach='median',\n",
    "        Percentage= lambda x: round((len(x) / total_count) * 100,1)\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca38fb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode: only_action_history_information\n",
      "[[[0.2 0.8]\n",
      "  [0.1 0.9]\n",
      "  [0.  1. ]\n",
      "  [0.  1. ]]\n",
      "\n",
      " [[0.1 0.9]\n",
      "  [0.2 0.8]\n",
      "  [0.4 0.6]\n",
      "  [0.1 0.9]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming required classes and functions are defined or imported\n",
    "# Initialize the ecological public goods game\n",
    "\n",
    "# List of modes to iterate through\n",
    "modes = ['only_action_history_information']\n",
    "\n",
    "# Data storage for results\n",
    "results_unique = {}\n",
    "results_all = {}\n",
    "obdsist_all = {}\n",
    "# Iterate through each mode\n",
    "\n",
    "for mode in modes:\n",
    "    # Initialize the information condition\n",
    "    information_condition_instance = Information_Conditions(ecopg, mode=mode)\n",
    "    mae = POstratAC_eps(env=information_condition_instance, learning_rates=0.1, discount_factors=0.9)\n",
    "\n",
    "    # Generate initial conditions using Latin hypercube sampling\n",
    "    num_samples = 8\n",
    "    initial_conditions_list = lhs_sampling(mae.Q, num_samples, mae.N)\n",
    "    # Print the mode\n",
    "    print(f\"\\nMode: {mode}\")\n",
    "\n",
    "    # Store unique points for this mode\n",
    "    final_point_list = []\n",
    "    obsdist_list = []\n",
    "\n",
    "    # Monte Carlo Simulations\n",
    "    for initial_condition in initial_conditions_list:\n",
    "        \n",
    "        initial_condition = make_degraded_state_cooperation_probablity_zero(initial_condition, information_condition_instance.Oset[0])\n",
    "\n",
    "        xtraj, fixedpointreached = mae.trajectory(initial_condition, Tmax=10000, tolerance=1e-5)\n",
    "        final_point = xtraj[-1]\n",
    "\n",
    "        # Round off to 4 decimal places\n",
    "        rounded_point = np.round(final_point, 1)\n",
    "        \n",
    "        #obsdist points \n",
    "        obsdist = mae.obsdist(final_point)\n",
    "        obsdist_list.append(obsdist)\n",
    "\n",
    "        # Get unique points\n",
    "        final_point_list.append(rounded_point)\n",
    "\n",
    "    # Save results for the current mode\n",
    "    results_unique[mode] = get_unique_arrays(final_point_list)\n",
    "    results_all[mode] = final_point_list\n",
    "    obdsist_all[mode] = obsdist_list\n",
    "\n",
    "# The `results` dictionary contains the processed unique points for each mode\n",
    "\n",
    "print(results_unique['only_action_history_information'][3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
