{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c240cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.ipynb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4e3bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_policy_for_given_observation_set(X, O):\n",
    "    \"\"\"\n",
    "    Takes in the strategy wrt to complete state set as input and returns the average strategy wrt to the given observation set. For example Strategty with respect to state set might\n",
    "    have c, c, g = 0.2 and c, c, p = 0.8. But the observation set will be c, c, if only actions are observed. Then the average strategy for this observation set would be 0.5\n",
    "\n",
    "    \"\"\"\n",
    "    A, S, F = X.shape        # Number of layers, states, and features\n",
    "    _, _, num_obs = O.shape   # Number of observations\n",
    "\n",
    "    # Initialize the output matrix with zeros\n",
    "    output = np.zeros((A, num_obs, F))\n",
    "\n",
    "    for i in range(A):\n",
    "        for obs in range(num_obs):\n",
    "            current_mask = O[i, :, obs]  # Shape: (S,)\n",
    "\n",
    "            # Select rows from X where mask is 1\n",
    "            selected_X = X[i][current_mask == 1]  # Shape: (num_selected_states, F)\n",
    "            if selected_X.size > 0:\n",
    "                mean_vector = selected_X.mean(axis=0)  # Shape: (F,)\n",
    "            else:\n",
    "                mean_vector = np.zeros(F)  # Default to zero vector\n",
    "            output[i, obs, :] = mean_vector\n",
    "\n",
    "    return output\n",
    "\n",
    " \n",
    "def generate_action_history_observation_set(stateset, number_of_agents):\n",
    "    action_histories = [state[:3] for state in stateset]\n",
    "    unique_action_histories = sorted(list(set(action_histories)))\n",
    "    Oset = [unique_action_histories.copy() for _ in range(number_of_agents)]\n",
    "    return Oset\n",
    "\n",
    "\n",
    "def generate_state_observation_set(stateset, number_of_agents):\n",
    "    state_histories = [state[4:] for state in stateset]\n",
    "    unique_state_histories = sorted(list(set(state_histories)))\n",
    "    Oset = [unique_state_histories.copy() for _ in range(number_of_agents)]\n",
    "    return Oset\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab51ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lhs_sampling(no_of_states, number_of_samples, agents):\n",
    "\n",
    "\n",
    "    global global_seed\n",
    "    number_of_dimensions_for_sampling = agents*no_of_states\n",
    "    sampler = qmc.LatinHypercube(d= number_of_dimensions_for_sampling, seed = global_seed if global_seed is not None else None)\n",
    "\n",
    "    # Sampling for each agent and stacking similar result lists\n",
    "    lhs_random_samples_list = sampler.random(number_of_samples)\n",
    "    result = [np.stack((random_samples, 1 - random_samples), axis=-1) for random_samples in lhs_random_samples_list]\n",
    "    reshaped_result = [random_samples.reshape(agents,no_of_states,2) for random_samples in result]\n",
    "    \n",
    "    # cross_product = [np.stack((x, y), axis=0) for x, y in it.combinations_with_replacement(result, agents)]\n",
    "\n",
    "    return reshaped_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lhs_sampling_structured(no_of_states, number_of_samples, agents):\n",
    "    global global_seed\n",
    "    sampler = qmc.LatinHypercube(d=no_of_states, seed = global_seed)\n",
    "\n",
    "    # Sampling for each agent and stacking similar result lists\n",
    "    lhs_random_samples_list = sampler.random(number_of_samples)\n",
    "    result = [np.stack((random_samples, 1 - random_samples), axis=-1) for random_samples in lhs_random_samples_list]\n",
    "    cross_product = [np.stack((x, y), axis=0) for x, y in it.combinations_with_replacement(result, agents)]\n",
    "\n",
    "    return cross_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ba122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_degraded_state_cooperation_probablity_zero(initial_condition, Oset):\n",
    "\n",
    "    degraded_mask = jnp.array(['g' in label for label in Oset])\n",
    "    initial_condition[:, degraded_mask, 0] = 0\n",
    "    initial_condition[:, degraded_mask, 1] = 1\n",
    "\n",
    "    return initial_condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc1f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_degraded_states_from_obsdist(obsdist, Oset):\n",
    "   \n",
    "        # Exclude degraded states from the observation distribution\n",
    "\n",
    "    degraded_mask = jnp.array(['g' in label for label in Oset])\n",
    "    obsdist = jnp.where(degraded_mask, 0, obsdist)\n",
    "\n",
    "    # Normalize rows to ensure sum of probabilities is 1\n",
    "    # row_sums = jnp.sum(obsdist, axis=1, keepdims=True)\n",
    "    # obsdist_without_degraded_state = jnp.where(row_sums > 0, obsdist / row_sums, obsdist)  # Avoid division by zero\n",
    "\n",
    "    return obsdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344abe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_average_cooperativeness(policy, obsdist, mode, Oset, exclude_degraded_state_for_average_cooperation):\n",
    "    \n",
    "    if exclude_degraded_state_for_average_cooperation:\n",
    "        if mode == 'only_state_information' or mode == 'both_state_and_action_information':\n",
    "            obsdist = exclude_degraded_states_from_obsdist(obsdist, Oset)\n",
    "\n",
    "        \n",
    "    policy_cooperation_probabilities = policy[:,:, 0]\n",
    "    agent_index, state_index = [0, 1]\n",
    "\n",
    "    average_cooperation_for_each_agent = jnp.einsum(policy_cooperation_probabilities, [agent_index, state_index], obsdist, [agent_index, state_index], [agent_index])\n",
    "    \n",
    "    return average_cooperation_for_each_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c4ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_unique_arrays(list_of_arrays):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        arrays (list of np.ndarray): List of NumPy arrays to check for uniqueness.\n",
    "\n",
    "    Returns:\n",
    "        list of np.ndarray: A list of unique arrays restored to their original shapes.\n",
    "    \"\"\"\n",
    "    list_of_unique_arrays = [list_of_arrays[0]]  #the first element of array is always uniqyue\n",
    "    for array in list_of_arrays:\n",
    "        is_unqiue = True\n",
    "        for unique_array in list_of_unique_arrays:\n",
    "            if  np.allclose(array, unique_array, rtol = 0.01) or  np.allclose(array, np.flip(unique_array, axis = 0), rtol = 0.01):\n",
    "                is_unqiue = False\n",
    "                break\n",
    "        if is_unqiue:            \n",
    "            list_of_unique_arrays.append(array)\n",
    "    return list_of_unique_arrays\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "770f6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_strategies_frequency(list_of_final_points):\n",
    "\n",
    "    strategy_shape = list_of_final_points[0].shape\n",
    "    total_number_of_strategies = len(list_of_final_points)\n",
    "\n",
    "    flattened_strategies = [tuple(point.flatten()) for point in list_of_final_points]\n",
    "    #flatten and make it to tuple, otherwise np.unqiue will do element wise\n",
    "    unique_strategies, counts = np.unique(flattened_strategies, axis = 0, return_counts=True)\n",
    "    #axis = 0 so that we are looking for unique rows (Hhere tuples rather than)\n",
    "    # formatted_strategies = [np.array2string(np.array(strategy).reshape(strategy_shape), max_line_width = np.inf) for strategy in unique_strategies]\n",
    "    strategy_frequencies = pd.DataFrame([{'strategy': strategy.reshape(strategy_shape), 'frequency': (count/total_number_of_strategies)*100} for strategy, count in zip(unique_strategies, counts)])\n",
    "    #reshape, then array2string to make it human readable, then dataframe for better visualization\n",
    "    return strategy_frequencies\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
